library(caret)
library(kernlab)
install.packages("kernlab")
library(kernlab)
data(spam)
inTrain<-createDataPartition(y=spam$type,p=0.75,list=F)
training<-spam[inTrain,]
testing<-spam[-inTrain,]
dim(training)
head(spam)
set.seed(32343)
modelFit<-train(type~.,data=training,method='glm')
install.packages("e1071")
modelFit<-train(type~.,data=training,method='glm')
modelFit
TP <- 99
FP <- 999
p <- TP/(TP + FP)
p
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
head(diagnosis)
head(diagnosis,20)
head(predictors)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[trainIndex,]
View(testing)
View(training)
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
View(testing)
View(training)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
names(training)
library(ggplot2)
q<-ggplot2(data=training,aes(x=Superplasticizer))
library(ggplot2)
q<-ggplot2(data=training,aes(x=Superplasticizer))
q<-ggplot(data=training,aes(x=Superplasticizer))
q+geom_histogram()
training1<-training
training1$Superplasticizer<-log(training$Superplasticizer)
q<-ggplot(data=training1,aes(x=Superplasticizer))
q+geom_histogram()
range(training$Superplasticizer)
range(training1$Superplasticizer)
training1$Superplasticizer<-log(training$Superplasticizer+1)
q<-ggplot(data=training1,aes(x=Superplasticizer))
q+geom_histogram()
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
names(predictors)
roi<-57:68
p<-predictors[,roi]
names(p)
preProc<-preprocess(p,method="pca")
preProc<-preProcess(p,method="pca")
test<-predict(preProc,training)
preProc<-preProcess(p,method="pca",pcaComp=2)
test<-predict(preProc,training)
str(p)
test<-predict(preProc,p)
head(preProc)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
names(predictors)
# note that the names that begin with "IL" are columns 57:68
roi<-57:68
p<-predictors[,roi]
prComp<-prcom(p)
prComp<-prcomp(p)
View(prComp)
plot(prComp$x[,1],prComp$x[,2])
prComp$rotation
pc<-prcomp(p)
pc[,1]
pc$x[,1]
sum(pc$x[,1])
pc$x %*% pc$x
pc$x %*% t(pc$x)
t(pc$x) %*% (pc$x)
confusionMatrix(testing)
preProc<-preProcess(p,method="pca",pcaComp=2)
test<-predict(preProc,p)
confusionMatrix(testing)
?preProcess
preProc<-preProcess(p,method="pca",thresh=0.8)
preProc$numComp
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
str(training)
exist(training$type)
training$type
training$diagnosis
modelFit1<-train(training$diagnosis~.,method="glm",data=training)
training[,1]
trainPC<-predict(preProc,training[,-1])
trainPC<-predict(preProc,log10(training[,-1]+1))
trainPC<-predict(preProc,training[,-1])
trainPC<-predict(preProc,predictors)
preProc<-preProcess(p,method="pca",thresh=0.8)
preProc$numComp
trainPC<-predict(preProc,predictors)
trainPC<-predict(preProc,training[,-1])
confusionMatrix(testing$diagnosis,predict(modelFit1,testing))
preProc
training[,-1]
dim(training[,-1])
dim(training)
trainPC<-predict(preProc,p)
?predict
trainPC
modelFit2<-train(training$diagnosis~.method="glm",data=trainPC)
modelFit2<-train(training$diagnosis~.,method="glm",data=trainPC)
testPC<-predict(preProc,testing[,-1])
testPC<-predict(preProc,testing[,roi])
trainPC<-predict(preProc,training[,roi])
testPC<-predict(preProc,testing[,roi])
preProc<-preProcess(p,method="pca",thresh=0.8)
preProc$numComp
trainPC<-predict(preProc,training[,roi])
testPC<-predict(preProc,testing[,roi])
trainPC<-predict(preProc,p)
modelFit2<-train(training$diagnosis~.,method="glm",data=trainPC)
modelFit2<-train(training$diagnosis~.,method="glm",data=p)
trainPC
dim(trainPC)
dim(training)
dim(p)
names(training)
training<-training[,roi]
training = adData[ inTrain,]
names(training)
roi<-58:69
training<-training[,roi]
training = adData[ inTrain,]
trainingIL<-training[,roi]
dim(trainingIL)
dim(training)
modelFit1<-train(training$diagnosis~.,method="glm",data=trainingIL)
confusionMatrix(testing$diagnosis,predict(modelFit1,testing))
trainPC<-predict(preProc,trainingIL)
preProc<-preProcess(trainingIL,method="pca",thresh=0.8)
trainPC<-predict(preProc,trainingIL)
modelFit2<-train(training$diagnosis~.,method="glm",data=trainPC)
confusionMatrix(testing$diagnosis,predict(modelFit2,testing))
modelFit2<-train(training$diagnosis~.,method="glm",data=trainPC)
confusionMatrix(testing$diagnosis,predict(modelFit2,testing))
confusionMatrix(testing$diagnosis,predict(modelFit2,trainPC))
testPC<-predict(preProc,testing[,-1])
testPC<-predict(preProc,testing[,roi])
confusionMatrix(testing$diagnosis,predict(modelFit2,testPC))
a<-confusionMatrix(testing$diagnosis,predict(modelFit2,testPC))
a$Accuracy
str(a)
summary(a)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
data(segmentationOriginal)
library(caret)
names(segmentationOriginal)
inTrain<-createDataPartition(y=segmentationOriginal$Case,p=0.7,list=FALSE)
inTrain<-createDataPartition(y=segmentationOriginal$Case,p=0.7,list=FALSE)
training<-segmentationOriginal[inTrain,]
testing<-segmentationOriginal[-inTrain,]
set.seed(125)
?train
?rpart
mod1<-train(Case~.,method="rpart",data=training)
print(mod1$finalModel)
plot(mod1$finalModel,uniform=TRUE,main="Classification Tree")
text(modFit$finalModel,use.n=TRUE,all=TRUE,cex=0.8)
text(mod1$finalModel,use.n=TRUE,all=TRUE,cex=0.8)
head(training)
View(training)
head(training$TotalIntench2)
head(training[,75:119])
summary(training$TotalIntench2)
summary(training$TotalIntenCh2)
sum(training$TotalIntenCh2==23000)
a0<-training[1,]
a<-a0
a$TotalIntenCh2<-23000
a<-a0
a$TotalIntenCh2<-23000
a$FiberWidthCh1
a$FiberWidthCh1<-10
a$PerimStatusCh1
a$PerimStatusCh1<-2
b$VarIntenCh4
b<-a0
b$VarIntenCh4
b$TotalIntenCh2<-50000
b$FiberWidthCh1<-10
b$VarIntenCh4<-100
c<-a0
c$TotalIntenCh2<-57000
c$FiberWidthCh1<-8
c$VarIntenCh4<-100
d$PerimStatusCh1
d<-a0
d$FiberWidthCh1<-8
d$VarIntenCh4<-100
d$PerimStatusCh1
d$PerimStatusCh1<-2
a0<-training[1,]
a<-a0
a$TotalIntenCh2<-23000
a$FiberWidthCh1<-10
a$PerimStatusCh1<-2
b<-a0
b$TotalIntenCh2<-50000
b$FiberWidthCh1<-10
b$VarIntenCh4<-100
c<-a0
c$TotalIntenCh2<-57000
c$FiberWidthCh1<-8
c$VarIntenCh4<-100
d<-a0
d$FiberWidthCh1<-8
d$VarIntenCh4<-100
d$PerimStatusCh1<-2
test1<-data.frame(a,b,c,d)
?data.frame
test1<-rbind(a,b,c,d)
predict(mod1,newdata=test1)
predict(mod1,newdata=training)
unique(training$Case)
predict(mod1,newdata=test1)
unique(training$Case)
inTrain<-segmentationOriginal$Case=="Train"
inTrain<-segmentationOriginal$Case=="Train"
training<-segmentationOriginal[inTrain,]
testing<-segmentationOriginal[-inTrain,]
# set seed to 125
set.seed(125)
mod1<-train(Case~.,method="rpart",data=training)
summary(training)
?segmentationOriginal
mod1<-train(Class~.,method="rpart",data=training)
install.packages("rattle")
fancyRpartPlot(mod1$finalModel)
library(rattle)
fancyRpartPlot(mod1$finalModel)
fancyRpartPlot(mod1$finalModel)
install.packages("rpart.plot")
fancyRpartPlot(mod1$finalModel)
library(AppliedPredictiveModeling)
install.packages("caret")
install.packages("AppliedPredictiveModeling")
install.packages("ggplot2")
install.packages("reshape2")
install.packages("rattle")
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
table(olive$Area)
data(olive)
head(olive)
summary(olive)
olive = olive[,-1]
summary(olive)
library(ggplot2)
qplot(Area,Palmitic,data=olive)
qplot(Palmitic,Palmitoleic,color=Area,data=olive)
modFit<-train(Area ~ ., method="rpart",data=olive)
library(caret)
modFit<-train(Area ~ ., method="rpart",data=olive)
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages("rpart.plot")
fancyRpartPlot(modFit$finalModel)
str(olive)
unique(olive$Area)
newdata = as.data.frame(t(colMeans(olive)))
predict(modFit,newData=newData)
predict(modFit,newdata=newdata)
olive$Area<-factor(olive$Area)
modFit<-train(Area ~ ., method="rpart",data=olive)
install.packages("e1071")
modFit<-train(Area ~ ., method="rpart",data=olive)
fancyRpartPlot(modFit$finalModel)
predict(modFit,newdata=newdata)
newdata = as.data.frame(t(colMeans(olive)))
hist(olive$Area)
data(olive)
olive = olive[,-1]
hist(olive$Area)
install.packages("shiny")
install.packages("kable")
?kable
df<-data.frame(x=c(1,2,4,0),y=c(0.5,1,2,0))
fit<-with(df,lm(y~x))
summary(fit)
plot(df)
abline(fit)
fit
h3<-function(t0,t1,x){
t0 + t1*x
}
h3(0,0.5,df$x)
h3(0,0.5,4)
h3(-1,0.5,4)
shiny::runApp('Data Science Specialization/Data Science Specialization Courses Master/09_DevelopingDataProducts/shiny/inputApp')
shiny::runApp('Data Science Specialization/Data Science Specialization Courses Master/09_DevelopingDataProducts/shiny/inputApp')
install.packages("manipulate")
?manipulate
library(manipulate)
?manipulate
manipulate(hist(runif(x)),x = slider(0,10))
manipulate(hist(runif(x),breaks=10),x = slider(0,10))
manipulate(hist(runif(x),breaks=10),x = slider(1,10))
manipulate(hist(runif(x),breaks=10),x = slider(1,10000))
manipulate(hist(runif(x),breaks=10),x = slider(1,100000))
install.packages("rcharts")
install.packages("devtools")
install_github('rCharts', 'ramnathv')
require(devtools)
library(devtools)
install_github('rCharts', 'ramnathv')
install.packages("googleVis")
suppressPackageStartupMessages(library(googleVis))
M<-gvisMotionChart(Fruits,"Fruit","Year",options=list(width=600,height=400))
print(M,"chart")
print(M,"chart")
suppressPackageStartupMessages(library(googleVis))
M<-gvisMotionChart(Fruits,"Fruit","Year",options=list(width=600,height=400))
print(M,"chart")
print(M,"chart")
plot(M,"chart")
plot(M,"chart")
suppressPackageStartupMessages(library(googleVis))
M <- gvisMotionChart(Fruits, "Fruit", "Year",
options=list(width=600, height=400))
print(M,"chart")
suppressPackageStartupMessages(library(googleVis))
M<-gvisMotionChart(Fruits,"Fruit","Year",options=list(width=600,height=400))
plot(M,"chart")
print(M,"chart")
print(M,"chart")
source('~/.active-rstudio-document')
library(devtools)
devtools::install_github('rstudio/shinyapps')
shinyapps::setAccountInfo(name='tboats', token='EE181971D4814F4D40535AEAAF3784EC', secret='udn89qZTmdZhFXeSgX9M2Emc08ZUcQGNOlRfZri7')
install.packages("plotly")
install_github("ropensci/plotly")
install_github("ropensci/plotly")
install.packages("stringi")
install_github("ropensci/plotly")
library(devtools)
install_github("ropensci/plotly")
library(plotly)
set_credentials_file("tboats", "52ywe8h8t4")
py <- plotly()
trace0 <- list(
x = c(1, 2, 3, 4),
y = c(10, 15, 13, 17)
)
trace1 <- list(
x = c(1, 2, 3, 4),
y = c(16, 5, 11, 9)
)
response <- py$plotly(trace0, trace1, kwargs=list(filename="basic-line", fileopt="overwrite"))
response$url
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
library(rCharts)
data(airquality)
dTable(airquality, sPaginationType = "full_numbers")
library(Rtools)
R.home()
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
oauth_endpoints("github")
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "63a9e52d62a8631dcd22",
secret = "a8d56079f3e2ec022ea780b127ed2f9a1dd66419")
# 3. Get OAuth credentials
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
library(Rcpp)
install.packages("Rcpp")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
content(req)
req
str(req)
content(req)
reqcontent<-content(req)
repocontent <- fromJSON(toJSON(reqcontent))
install.packages("RJSONIO")
library(RJSONIO)
repocontent <- fromJSON(toJSON(reqcontent))
repoconent
repocontent
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
content(req)
content(req)[[30]]
content(req)[[30,"created_at"]]
content(req)[30,"created_at"]
content(req)[[30]]$created_at
content(req)
content(req)[[1]]$created_at
content(req)[[2]]$created_at
content(req)[[3]]$created_at
for (i in 1:30){
content(req)[[i]]$created_at
}
for (i in 1:30){
print(content(req)[[i]]$created_at)
}
content(req)[[6]]$created_at
content(req)[[1]]
with(iris,tapply(Sepal.Length,Species,mean))
set.seed(1)
rpois(5, 2)
rpois(5, 2)
set.seed(1)
rpois(5, 2)
rpois(5, 2)
rpois(5, 2)
rnorm(1)
rnorm(10)
rands<-rnorm(1000)
hist(rands,breaks=100)
?ppois
dpois(seq(0,100,10),1)
dpois(seq(0,110,10),1)
ppois(seq(0,110,10),1)
plot(ppois(seq(0,1,0.01),1))
# Which function can be used to evaluate the inverse cumulative distribution function for the Poisson distribution?
# ppois
# dpois
# rpois
# qpois
ppois(seq(0,1,0.01),1)
seq(0,1,0.01)
plot(ppois(seq(0,100,1),1))
plot(ppois(seq(-10,100,1),1))
pnorm(0)
qpois(3,1)
qpois(1,1)
qpois(2,1)
qpois(0.5,1)
qpois(0.1,1)
qpois(0.2,1)
qpois(0.7,1)
qnorm(1,0)
qnorm(1,1)
qnorm(0.5,1)
qnorm(0.5,0)
qnorm(1,0)
qnorm(0.01,mean=1)
qpois(0.5,100)
qpois(0.99,100)
x <- rep(0:1, each = 5)
x
set.seed(10)
x <- rep(0:1, each = 5)
e <- rnorm(10, 0, 20)
y <- 0.5 + 2 * x + e
plot(x,y)
e <- rnorm(10, 0, 2)
y <- 0.5 + 2 * x + e
plot(x,y)
library(datasets)
Rprof()
fit <- lm(y ~ x1 + x2)
Rprof(NULL)
setwd("E:/Dropbox/R/Data Science Specialization/getting and cleaning data/course project")
